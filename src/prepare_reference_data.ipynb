{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import AxesImage, NonUniformImage\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.interpolate import interp1d\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(),'..'))\n",
    "from lib import find_nearest_index, FigureSize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OUTPUTS = 26 # no. of peaks\n",
    "NUM_BATCHES = 32\n",
    "NUM_EPOCHS = 10\n",
    "IMAGE_SIZE = 32\n",
    "NUM_TRAIN_LABELS = 2600 # use outpuf of load_images()\n",
    "\n",
    "TRAIN_DATA_PATH= os.path.join(os.getcwd(), '..','data','train')\n",
    "MODEL_PATH = os.path.join(os.getcwd(), '..','data','model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEON_REFERENCE_FILE = os.path.join(os.getcwd(),'..','data','ref','NIST','Ne','neon-exported.csv')\n",
    "WAVELENGTHS_MIN, WAVELENGTHS_MAX = 4000, 9000\n",
    "WINDOW = 256\n",
    "STEPSIZE_MIN, STEPSIZE_MAX, STEPSIZE_N = 0.7, 1.3, 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Reshape((IMAGE_SIZE,IMAGE_SIZE,1),input_shape=(IMAGE_SIZE,IMAGE_SIZE,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(5,5), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))         \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1024))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    # model.add(tf.keras.layers.Dense(NUM_TRAIN_LABELS, activation='softmax')) \n",
    "    model.add(tf.keras.layers.Dense(NUM_OUTPUTS, activation='softmax')) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(path):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "\n",
    "    dir_index = 0\n",
    "    for directory in sorted(os.listdir(path)):\n",
    "        if(directory.startswith('.') == False):\n",
    "\n",
    "            #print(\"Buchstabe: {}\".format(LIST_OF_CHARS[dir_index]))\n",
    "            for filename in sorted(os.listdir(os.path.join(path, directory))):\n",
    "\n",
    "                if(filename.startswith('.') == False):\n",
    "                        \n",
    "                        image_path = os.path.join(path, directory,filename    )\n",
    "                        img =cv2.imread(image_path)\n",
    "                        img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                        img = img.reshape([IMAGE_SIZE, IMAGE_SIZE,1])\n",
    "                        train_images.append(img)\n",
    "                        train_labels.append(dir_index)\n",
    "            dir_index = dir_index + 1\n",
    "\n",
    "    print(len(train_images),train_labels)\n",
    "    return np.array(train_images)/255, np.array(tf.keras.utils.to_categorical(train_labels,NUM_OUTPUTS))#len(train_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neon_reference_file = os.path.join(NEON_REFERENCE_FILE)\n",
    "positions = {'wavelength':2, 'intensity':6, 'selector':1}\n",
    "selector = '1'\n",
    "intensity_limit = 1.0\n",
    "neon_wavelengths = []\n",
    "neon_intensities = []\n",
    "\n",
    "with open(neon_reference_file,'r') as neon_f:\n",
    "    for line in neon_f:\n",
    "        if line.startswith('#'):\n",
    "            pass\n",
    "        else:\n",
    "            tokens =  line.split(';')\n",
    "            #print (tokens)\n",
    "            try:\n",
    "                if selector in tokens[positions['selector']] :\n",
    "                    \n",
    "                    neon_wavelength, neon_intensity = float(tokens[positions['wavelength']]), float(tokens[positions['intensity']])\n",
    "                    \n",
    "                    if neon_intensity > intensity_limit :\n",
    "                        \n",
    "                        neon_wavelengths.append(neon_wavelength)\n",
    "                        neon_intensities.append(neon_intensity)\n",
    "                        \n",
    "                        print (\"{:8.3f} {:10.0f}\".format(neon_wavelength, neon_intensity, ))\n",
    "                    \n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "print (len(neon_wavelengths), len(neon_intensities))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neon_reference_file = 'linetable-NE.csv'\n",
    "positions = {'wavelength':0, 'intensity':2}\n",
    "neon_wavelengths = []\n",
    "neon_intensities = []\n",
    "\n",
    "with open(neon_reference_file,'r') as neon_f:\n",
    "    for line in neon_f:\n",
    "        if line.startswith('#'):\n",
    "            pass\n",
    "        else:\n",
    "            tokens =  line.split(';')\n",
    "            print (tokens)\n",
    "            try:\n",
    "                neon_wavelength, neon_intensity = float(tokens[positions['wavelength']]), float(tokens[positions['intensity']])\n",
    "                neon_wavelengths.append(neon_wavelength)\n",
    "                neon_intensities.append(neon_intensity)\n",
    "                \n",
    "                print (\"{:8.3f} {:10.0f}\".format(neon_wavelength, neon_intensity, ))\n",
    "                \n",
    "                        \n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "print (len(neon_wavelengths), len(neon_intensities))\n",
    "#\n",
    "# print (neon_wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = np.array(range(WAVELENGTHS_MIN,WAVELENGTHS_MAX,1))*1.0\n",
    "intensities = wavelengths * 0.0\n",
    "sigma = 4.0\n",
    "k = -2*sigma*sigma\n",
    "r = math.sqrt(2*math.pi*sigma*sigma)\n",
    "\n",
    "for neon_w, neon_i, in zip(neon_wavelengths, neon_intensities):\n",
    "\n",
    "    _e = (wavelengths - neon_w)*(wavelengths- neon_w) / k\n",
    "    intensities = intensities + np.exp(_e) * neon_i\n",
    "        \n",
    "\n",
    "xlim = [wavelengths[1], wavelengths[-2]]\n",
    "_i1 = find_nearest_index(wavelengths,xlim[0])\n",
    "_i2 = find_nearest_index(wavelengths,xlim[1])\n",
    "#print (_i1[0], _i2[0])\n",
    "max_i = intensities[_i1:_i2].max()\n",
    "normalized_intensities = intensities / max_i\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(wavelengths, normalized_intensities)\n",
    "for _nw, _ni in zip(neon_wavelengths, neon_intensities):\n",
    "    plt.text(_nw,_ni/max_i,\"{:6.1f}\".format(_nw), rotation=90, horizontalalignment='center')\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(0,1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelengths = np.array(range(WAVELENGTHS_MIN,WAVELENGTHS_MAX,1))*1.0\n",
    "pixels = np.array(range(0,len(wavelengths)))\n",
    "intensities = wavelengths * 0.0\n",
    "sigma = 4.0\n",
    "k = -2*sigma*sigma\n",
    "r = math.sqrt(2*math.pi*sigma*sigma)\n",
    "\n",
    "for neon_w, neon_i, in zip(neon_wavelengths, neon_intensities):\n",
    "\n",
    "    _e = (wavelengths - neon_w)*(wavelengths- neon_w) / k\n",
    "    intensities = intensities + np.exp(_e) * neon_i\n",
    "\n",
    "xlim = [wavelengths[1], wavelengths[-2]]\n",
    "_i1 = find_nearest_index(wavelengths,xlim[0])\n",
    "_i2 = find_nearest_index(wavelengths,xlim[1])\n",
    "max_i = intensities[_i1:_i2].max()\n",
    "normalized_intensities = intensities / max_i\n",
    "\n",
    "ny = WINDOW\n",
    "nx = len(normalized_intensities)\n",
    "\n",
    "twod = np.zeros((ny, nx))\n",
    "for i in range(ny):\n",
    "    twod[i] = normalized_intensities*-1+1.0\n",
    "\n",
    "ylim = [0,ny]\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = math.ceil(len(neon_wavelengths)/n_cols)\n",
    "\n",
    "window = WINDOW\n",
    "window_h = int(window/2)\n",
    "image_size = [IMAGE_SIZE,IMAGE_SIZE]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = FigureSize.LARGE\n",
    "fig, axes = plt.subplots(n_rows, n_cols,sharex=False, sharey=False)\n",
    "\n",
    "i_row = 0\n",
    "i_col = 0\n",
    "\n",
    "for index in range(0,len(neon_wavelengths)):\n",
    "    neon_w = neon_wavelengths[index]\n",
    "    \n",
    "    _xlim = [\n",
    "            find_nearest_index(wavelengths,neon_w)-window_h,\n",
    "            find_nearest_index(wavelengths,neon_w)+window_h,\n",
    "    ]\n",
    "    _ylim = [0,ny]\n",
    "    _twod = twod[_ylim[0]:_ylim[1], _xlim[0]:_xlim[1]]\n",
    "    wavelength_text = str(int(neon_w*100)/100)\n",
    "    print(index, neon_w, wavelength_text, _xlim)\n",
    "    \n",
    "\n",
    "    if n_cols == 1:\n",
    "        axes[i_row].imshow(_twod, cmap='gray')\n",
    "        axes[i_row].set_title(wavelength_text)\n",
    "        axes[i_row].set_ylim(_ylim)\n",
    "        axes[i_row].set_xlim(0,_xlim[1]-_xlim[0])\n",
    "        print (i_row, wavelength_text, _xlim)\n",
    "        i_row += 1\n",
    "    else:\n",
    "        axes[i_row, i_col].imshow(_twod, cmap='gray')\n",
    "        axes[i_row, i_col].set_title(wavelength_text)\n",
    "        axes[i_row, i_col].set_ylim(_ylim)\n",
    "        axes[i_row, i_col].set_xlim(0,_xlim[1]-_xlim[0])\n",
    "\n",
    "        i_col += 1\n",
    "        if i_col >= n_cols:\n",
    "            i_col = 0\n",
    "            i_row +=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neon_w in neon_wavelengths:\n",
    "    wavelength_text = str(int(neon_w*100)/100)\n",
    "    p = os.path.join(TRAIN_DATA_PATH, wavelength_text)\n",
    "    try:\n",
    "        shutil.rmtree(p, ignore_errors=True)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print (\"skipping \"+p)\n",
    "    os.mkdir(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 4.0\n",
    "k = -2*sigma*sigma\n",
    "r = math.sqrt(2*math.pi*sigma*sigma)\n",
    "\n",
    "xlim = [wavelengths[1], wavelengths[-2]]\n",
    "ny = WINDOW\n",
    "nx = len(normalized_intensities)\n",
    "ylim = [0,ny]\n",
    "\n",
    "\n",
    "window = WINDOW\n",
    "window_h = int(window/2)\n",
    "image_size = [IMAGE_SIZE,IMAGE_SIZE]\n",
    "\n",
    "filename_counter = [0] * len (neon_wavelengths)\n",
    "\n",
    "min_stepsize = STEPSIZE_MIN\n",
    "max_stepsize = STEPSIZE_MAX\n",
    "n_steps = STEPSIZE_N\n",
    "d_step = (max_stepsize - min_stepsize)/n_steps\n",
    "\n",
    "stepsizes = np.array(range(n_steps))*d_step+min_stepsize\n",
    "#print (stepsizes)\n",
    "nbins = WAVELENGTHS_MAX - WAVELENGTHS_MIN\n",
    "for stepsize in stepsizes:\n",
    "    wavelengths = np.array(range(nbins))*stepsize+WAVELENGTHS_MIN #   np.array(range(4000,9000,stepsize))*1.0\n",
    "    \n",
    "    intensities = np.zeros(nbins)\n",
    "\n",
    "    for neon_w, neon_i, in zip(neon_wavelengths, neon_intensities):\n",
    "        \n",
    "        _e = (wavelengths - neon_w)*(wavelengths- neon_w) / k\n",
    "        intensities = intensities + np.exp(_e) * neon_i\n",
    "\n",
    "    max_i = intensities[1:-2].max()\n",
    "    normalized_intensities = intensities / max_i\n",
    "\n",
    "    twod = np.zeros((ny, nx))\n",
    "    for i in range(ny):\n",
    "        twod[i] = normalized_intensities*-1+1.0\n",
    "\n",
    "\n",
    "    for index in range(0,len(neon_wavelengths)):\n",
    "        neon_w = neon_wavelengths[index]\n",
    "        \n",
    "        _xlim = [\n",
    "            find_nearest_index(wavelengths,neon_w)-window_h,\n",
    "            find_nearest_index(wavelengths,neon_w)+window_h,\n",
    "        ]\n",
    "        _ylim = [0,ny]\n",
    "        _twod = twod[_ylim[0]:_ylim[1], _xlim[0]:_xlim[1]]\n",
    "        wavelength_text = str(int(neon_w*100)/100)\n",
    "        \n",
    "        p = os.path.join(TRAIN_DATA_PATH,wavelength_text,'{:s}.{:06d}.BMP'.format(wavelength_text,filename_counter[index]))\n",
    "\n",
    "        res = cv2.resize(np.uint8(_twod * 255), dsize=(IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "        img = Image.fromarray(res)\n",
    "        \n",
    "        img.save(p, format='BMP')\n",
    "        \n",
    "        filename_counter[index] += 1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels  = load_images(TRAIN_DATA_PATH)\n",
    "\n",
    "\n",
    "train_images, train_labels  = shuffle(train_images,train_labels,random_state=21)\n",
    "print (len(train_labels))\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(train_images, train_labels, test_size = 0.2, random_state = 0)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
    "model.fit(xTrain,yTrain, epochs=NUM_EPOCHS,batch_size=NUM_BATCHES,verbose=1,validation_split=0.2)\n",
    "\n",
    "results = model.evaluate(xTest,yTest,verbose=1)\n",
    "print(\"--- Ergebnisse {} ----\".format(TRAIN_DATA_PATH))\n",
    "print('Evaluation / Loss {}, Acc:{}'.format(results[0],results[1]))\n",
    "export_path = MODEL_PATH\n",
    "\n",
    "model.save(export_path)\n",
    "print(\"💾 Modell gespeichert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d499eb6db3777fdf4e4e943312bd37ba260a38bd75a3963efef353b7cf2eca9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
